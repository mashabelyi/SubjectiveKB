"""
Util functions for training
"""
import os
from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter

import torch.optim as optim
from torch.nn import MarginRankingLoss
from logger import Logger
from batching import BatchLoader


def parse_args():
	parser = ArgumentParser("TransE", formatter_class=ArgumentDefaultsHelpFormatter, conflict_handler='resolve')

	# REQUIRED params
	parser.add_argument("--data", default="data/yelp", help="Data sources.", required=True)
	parser.add_argument("--name", default="my_model", required=True, help="Model name. Will store model files in directory with name ")
	parser.add_argument("--model", default="transE", required=True, choices=['transE', 'subjD', 'subjM', 'ff', 'ffs', 'hyte', 'transH'], help="Options: transE, subjKB_D, subjKB_M")
	parser.add_argument("--mode", default="train", required=True, choices=['train', 'val', 'test', 'train-val'], help="Options: train, val, test")

	# OPTIONAL params
	parser.add_argument("--pretrained", help="Checkpoint of pretrained model (transE)")

	parser.add_argument("--batch_size", default=128, type=int, help="Batch Size")
	parser.add_argument("--neg_ratio", default=1.0, type=float, help="Number of negative triples generated by positive")
	parser.add_argument("--margin", default=1.0, type=float, help="Margin")
	parser.add_argument("--norm", default=2, type=float, help="L-norm (1 or 2) used in TransE scoring function")
	parser.add_argument("--patience", default=10, type=int, help="Stop training after no improvement in validation loss for this many epochs")
	parser.add_argument("--learning_rate", default=0.001, type=float, help="Learning rate")
	parser.add_argument("--num_epochs", default=200, type=int, help="Number of training epochs")
	# parser.add_argument("--validation_step", default=1, type=int, help="Number of epochs to train between validations")
	parser.add_argument("--embedding_dim", default=100, type=int, help="Dimensionality of character embedding")
	# parser.add_argument("--init_pretrained", default=False, help="Load in pretrained embeddings from tok2vec.init", action="store_true")
	parser.add_argument("--l2reg", default=0.1, type=float, help="L-2 regularization term")
	parser.add_argument("--optim", default='adam', type=str, help="Optimizer", choices=['sgd', 'adam', 'adagrad'])

	parser.add_argument("--test_pkl", required=False, help="Path to pickle file with test dict")
	parser.add_argument("--val_pkl", required=False, help="Path to pickle file with val dict")

	parser.add_argument("--eval_result", required=False, help="file where to save evaluation result")

	# DEV params
	parser.add_argument("--debug_nTrain", default=-1, type=int, help="Num training samples to use")
	parser.add_argument("--debug_nVal", default=-1, type=int, help="Num validation samples to use")
	parser.add_argument("--debug_nTest", default=-1, type=int, help="Num test samples to use")

	parser.add_argument("--f", default=False, help="Force overwrite existing data folder", action="store_true")

	args = parser.parse_args()
	print(args)

	return args


def create_model_folder(path, overwrite=False):
	if os.path.exists(path) and not overwrite:
		overwrite = input("\noverwrite existing model folder '{}'? type y/n: ".format(path))
		if overwrite!='y':
			print("choose a different model name (--name)")
			exit(0)
	else:
		if not os.path.exists(path):
			os.makedirs(path)
			model_dir = path



def setup(args):

	# Logger
	logger = Logger(args.name, ['loss', 'val_loss', 'MR', 'MRR', 'h@10'])
	
	# Loss function
	criterion = MarginRankingLoss(args.margin, reduction='sum')

	# Batch loader
	loader = BatchLoader(train, bernoulli_p, goldens, all_ents, all_sources, batch_size=args.batch_size, neg_ratio=args.neg_ratio)


	return logger, criterion, optimizer, loader